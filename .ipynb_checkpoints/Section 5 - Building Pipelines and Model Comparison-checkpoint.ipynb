{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1-4 - Building Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV reviews the performance of a set range of parameters on a cross-validation basis. This means only a portion of the training data is reviewed at any one time. When filling in the NA values with the mean value, however, we considered the whole set of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we took an inconsistent approach in reviewing only a portion of the data when running GridSearchCV, but the full set of data when filling in missing values. We can avoid this inconsistency by building pipelines and making imputations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will leave the NA values in the column Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:198: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the NA values in the column Age with a negative value marker -1, as the following bug disallows us from using a missing value marker:\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/3044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then review our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived       891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Gender         891 non-null int64\n",
      "Embarked_C     891 non-null float64\n",
      "Embarked_Q     891 non-null float64\n",
      "Embarked_S     891 non-null float64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 83.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a pipeline to enable us to first impute the mean value of the column Age on the portion of the training data we are considering, and second, assess the performance of our tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building a pipeline for random forest model (rf)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "imputer = Imputer(strategy='mean', missing_values=-1)\n",
    "scaler = StandardScaler()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('imp', imputer),\n",
    "    ('rf', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : \n",
      "0.854096520763\n"
     ]
    }
   ],
   "source": [
    "# Building a pipeline for SVM classification model (svc)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# ANOVA SVM-C\n",
    "anova_filter = SelectKBest(f_regression)\n",
    "clf = SVC(kernel='rbf')\n",
    "pipeline_svm = Pipeline([\n",
    "        ('impute', imputer),\n",
    "        ('scale', scaler), \n",
    "        ('anova', anova_filter), \n",
    "        ('svc', clf)\n",
    "    ])\n",
    "\n",
    "# You can set the parameters using the names issued\n",
    "# For instance, fit using a k of 10 in the SelectKBest\n",
    "# and a parameter 'C' of the svm\n",
    "pipeline_svm.set_params(anova__k=8, svc__C=10, svc__gamma=0.1).fit(train_data[0::,2::], train_data[0::,0])\n",
    "prediction = pipeline_svm.predict(train_data[0::,2::])\n",
    "print 'Training accuracy : '\n",
    "print(pipeline_svm.score(train_data[0::,2::], train_data[0::,0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now setup parameter grid and run GridSearchCV as before but replacing the classifier with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] rf__max_depth=5, rf__n_estimators=50 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=50, score=0.832402 -   0.1s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=50 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=50, score=0.804469 -   0.1s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=50 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=50, score=0.820225 -   0.1s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=50 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=50, score=0.797753 -   0.1s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=50 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=50, score=0.870056 -   0.1s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=100 ...........................\n",
      "[CV] .. rf__max_depth=5, rf__n_estimators=100, score=0.798883 -   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=100 ...........................\n",
      "[CV] .. rf__max_depth=5, rf__n_estimators=100, score=0.815642 -   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=100 ...........................\n",
      "[CV] .. rf__max_depth=5, rf__n_estimators=100, score=0.820225 -   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=100 ...........................\n",
      "[CV] .. rf__max_depth=5, rf__n_estimators=100, score=0.792135 -   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=100 ...........................\n",
      "[CV] .. rf__max_depth=5, rf__n_estimators=100, score=0.836158 -   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=1000 ..........................\n",
      "[CV] . rf__max_depth=5, rf__n_estimators=1000, score=0.810056 -   2.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=1000 ..........................\n",
      "[CV] . rf__max_depth=5, rf__n_estimators=1000, score=0.826816 -   1.6s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=1000 ..........................\n",
      "[CV] . rf__max_depth=5, rf__n_estimators=1000, score=0.831461 -   1.6s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=1000 ..........................\n",
      "[CV] . rf__max_depth=5, rf__n_estimators=1000, score=0.786517 -   2.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=1000 ..........................\n",
      "[CV] . rf__max_depth=5, rf__n_estimators=1000, score=0.841808 -   1.9s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=50 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=50, score=0.782123 -   0.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=50 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=50, score=0.815642 -   0.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=50 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=50, score=0.870787 -   0.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=50 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=50, score=0.775281 -   0.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=50 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=50, score=0.830508 -   0.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=100 ........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=100, score=0.798883 -   0.2s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=100 ........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=100, score=0.815642 -   0.2s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=100 ........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=100, score=0.842697 -   0.2s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=100 ........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=100, score=0.780899 -   0.2s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=100 ........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=100, score=0.824859 -   0.2s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=1000 .......................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=1000, score=0.787709 -   2.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=1000 .......................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=1000, score=0.815642 -   1.8s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=1000 .......................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=1000, score=0.859551 -   1.8s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=1000 .......................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=1000, score=0.769663 -   2.1s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=1000 .......................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=1000, score=0.836158 -   1.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.824915824916\n",
      "{'rf__max_depth': 5, 'rf__n_estimators': 50}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=4, svc__C=0.1, score=0.793296 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=4, svc__C=0.1, score=0.804469 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=4, svc__C=0.1, score=0.769663 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=4, svc__C=0.1, score=0.752809 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=4, svc__C=0.1, score=0.790960 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=4, svc__C=0.1, score=0.726257 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=4, svc__C=0.1, score=0.793296 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=4, svc__C=0.1, score=0.775281 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=4, svc__C=0.1, score=0.775281 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=4, svc__C=0.1, score=0.819209 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=4, svc__C=10, score=0.748603 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=4, svc__C=10, score=0.798883 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=4, svc__C=10, score=0.792135 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=4, svc__C=10, score=0.769663 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=4, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=4, svc__C=10, score=0.819209 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=4, svc__C=10, score=0.731844 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=4, svc__C=10, score=0.759777 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=4, svc__C=10, score=0.820225 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=4, svc__C=10, score=0.808989 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=4, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=4, svc__C=10, score=0.819209 -   0.2s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.793296 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.804469 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.769663 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.775281 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.790960 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.754190 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.815642 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.831461 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.775281 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.802260 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.798883 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ..........................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 jobs       | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.821229 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.831461 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.780899 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.841808 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.798883 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.743017 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.814607 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.786517 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.824859 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=7, svc__C=0.1, score=0.793296 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=7, svc__C=0.1, score=0.810056 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=7, svc__C=0.1, score=0.769663 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=7, svc__C=0.1, score=0.775281 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=7, svc__C=0.1, score=0.802260 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=7, svc__C=0.1, score=0.765363 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=7, svc__C=0.1, score=0.804469 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=7, svc__C=0.1, score=0.758427 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=7, svc__C=0.1, score=0.747191 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=7, svc__C=0.1, score=0.734463 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=7, svc__C=10, score=0.765363 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=7, svc__C=10, score=0.821229 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=7, svc__C=10, score=0.820225 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=7, svc__C=10, score=0.769663 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=7, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=7, svc__C=10, score=0.830508 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=7, svc__C=10, score=0.759777 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=7, svc__C=10, score=0.770950 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=7, svc__C=10, score=0.803371 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=7, svc__C=10, score=0.792135 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=7, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=7, svc__C=10, score=0.802260 -   0.1s\n",
      "0.814814814815\n",
      "{'svc__gamma': 0.1, 'anova__k': 6, 'svc__C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_dict = {'rf': pipeline_rf, 'svm': pipeline_svm} \n",
    "parameter_grid_dict = {}\n",
    "parameter_grid_dict['rf'] = {\n",
    "            'rf__n_estimators': [50, 100, 1000],\n",
    "            'rf__max_depth': [5, None],\n",
    "        }\n",
    "\n",
    "parameter_grid_dict['svm'] = {\n",
    "            'anova__k': [4, 6, 7],\n",
    "            'svc__C': [0.1, 10],\n",
    "            'svc__gamma': [0.1, 1]\n",
    "        }\n",
    "\n",
    "grid_results = {}\n",
    "for alg in ['rf', 'svm']:\n",
    "    pipeline = pipeline_dict[alg]\n",
    "    parameter_grid = parameter_grid_dict[alg]    \n",
    "    grid_search = GridSearchCV(pipeline, parameter_grid, cv=5, verbose=3)\n",
    "    grid_search.fit(train_data[0::,2::], train_data[0::,0])\n",
    "\n",
    "    sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    grid_results[alg] = grid_search    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for rf :\n",
      "0.824915824916\n",
      "{'rf__max_depth': 5, 'rf__n_estimators': 50}\n",
      "Best accuracy for svm :\n",
      "0.814814814815\n",
      "{'svc__gamma': 0.1, 'anova__k': 6, 'svc__C': 10}\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# Analysis of the results from pipelines\n",
    "\n",
    "for alg in grid_results:\n",
    "    grid_search = grid_results[alg]\n",
    "    sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "    print 'Best accuracy for %s :' % alg\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('impute', Imputer(axis=0, copy=True, missing_values=-1, strategy='mean', verbose=0)), ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('anova', SelectKBest(k=6, score_func=<function f_regression at 0x10724fb18>)), ('svc', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the parameters of the models to the best ones selected from grid search\n",
    "pipeline_rf.set_params(rf__n_estimators=50, rf__max_depth=5)\n",
    "pipeline_svm.set_params(anova__k=6, svc__C=10, svc__gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compare performance of different models, perform CV using the best hyper-parameters selected using grid search based on the previous pipeline analysis. This time we use 10-fold CV instead of 5-fold CV in order to get more  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StratifiedKFold' object has no attribute 'label_test_folds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-7574e966874b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_test_folds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'StratifiedKFold' object has no attribute 'label_test_folds'"
     ]
    }
   ],
   "source": [
    "scv1.label_test_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # Get prediction on class label from the model\n",
    "    y_prediction = pipeline.predict(X_test)\n",
    "    \n",
    "    # Get probability or decision function output from the model\n",
    "    try:\n",
    "         y_out = pipeline.predict_proba(X_test)[:,1]                     \n",
    "    except AttributeError:\n",
    "         print \"No probability output, use decision function instead!\"\n",
    "         y_out = pipeline.decision_function(X_test)\n",
    "    \n",
    "    acc = np.sum(y_test == y_prediction)*1./len(y_test)\n",
    "    print \"Prediction accuracy:\", acc\n",
    "    # Compute area under the ROC curve (AUC)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_out)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"Area under ROC curve (AUC):%s\"%roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.StratifiedKFold(labels=[ 0.  1.  1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.  1.\n",
      "  0.  1.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.\n",
      "  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  1.\n",
      "  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.\n",
      "  1.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.\n",
      "  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.\n",
      "  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.\n",
      "  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  0.  1.\n",
      "  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  0.  1.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.\n",
      "  1.  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.\n",
      "  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.\n",
      "  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.\n",
      "  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.\n",
      "  1.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.\n",
      "  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  1.  0.], n_folds=5, shuffle=False, random_state=1234)\n",
      "--- CV using rf ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-7d3e72f06e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m'--- CV using %s ---'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold as SKFold\n",
    "#from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "\n",
    "#pipeline_rf.set_params([grid_results[0].best_params_])\n",
    "#pipeline_svm.set_params(grid_results[1].best_params_)\n",
    "\n",
    "X = train_data[0:, 2:]\n",
    "y = train_data[0:, 0]\n",
    "\n",
    "scv1 = SKFold(y=y, n_folds=5, random_state=1234)\n",
    "scv2 = SKFold(y=y, n_folds=5, random_state=5678)\n",
    "\n",
    "print(scv1)\n",
    "\n",
    "def getAccAuc(pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # Get prediction on class label from the model\n",
    "    y_prediction = pipeline.predict(X_test)\n",
    "    \n",
    "    # Get probability or decision function output from the model\n",
    "    try:\n",
    "         y_out = pipeline.predict_proba(X_test)[:,1]                     \n",
    "    except AttributeError:\n",
    "         print \"No probability output, use decision function instead!\"\n",
    "         y_out = pipeline.decision_function(X_test)\n",
    "    \n",
    "    acc = np.sum(y_test == y_prediction)*1./len(y_test)\n",
    "    print \"Prediction accuracy:\", acc\n",
    "    # Compute area under the ROC curve (AUC)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_out)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"Area under ROC curve (AUC):%s\"%roc_auc)\n",
    "    return([acc, roc_auc])\n",
    "\n",
    "\n",
    "pipeline_dict = {'rf': pipeline_rf, 'svm': pipeline_svm}\n",
    "acc_dict = {}\n",
    "auc_dict = {}\n",
    "for alg in ['rf', 'svm']:  \n",
    "  pipeline = pipeline_dict[alg]\n",
    "  mean_acc = 0.0\n",
    "  mean_auc = 0.0\n",
    "  all_tpr = []\n",
    "  all_acc = []\n",
    "  all_auc = []\n",
    "  i = 0\n",
    "  print '--- CV using %s ---' % alg\n",
    "  for training_set, test_set in scv:\n",
    "    i+=1\n",
    "    X_train = X[training_set]\n",
    "    y_train = y[training_set]\n",
    "    X_test = X[test_set]\n",
    "    y_test = y[test_set]\n",
    "    #model = RandomForestClassifier(n_estimators=100)\n",
    "    #model.fit(X_train, y_train)\n",
    "\n",
    "    getAccAuc(pipeline, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_auc.append(roc_auc)\n",
    "    acc_dict[alg] = all_acc\n",
    "    auc_dict[alg] = all_auc\n",
    "  \n",
    "  all_acc=np.asarray(all_acc)\n",
    "  all_auc=np.asarray(all_auc)\n",
    "  print(all_acc)\n",
    "  # print 95% C.I. for both accuracy and AUC based on CV\n",
    "  print(\"Mean Accuracy: %0.2f (+/- %0.2f)\" % (all_acc.mean(), all_acc.std() * 1.96))\n",
    "  print(all_auc)\n",
    "  print(\"Mean AUC: %0.2f (+/- %0.2f)\" % (all_acc.mean(), all_auc.std() * 1.96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can start to compare the CV performance for the two type of models: rf and svm using one sapmel (student) t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% C.I. for both accuracy and AUC based on CV\n",
      "Mean Accuracy: 0.83 (+/- 0.08)\n",
      "[ 0.82753247  0.83792208  0.75588235  0.91550802  0.89358289  0.87433155\n",
      "  0.85508021  0.90588235  0.93235294  0.89106754]\n",
      "Mean AUC: 0.83 (+/- 0.10)\n",
      "95% C.I. for both accuracy and AUC based on CV\n",
      "Mean Accuracy: 0.81 (+/- 0.06)\n",
      "[ 0.82753247  0.84831169  0.76283422  0.86122995  0.89358289  0.81631016\n",
      "  0.75882353  0.74973262  0.84759358  0.89052288]\n",
      "Mean AUC: 0.81 (+/- 0.10)\n",
      "Test the hypothesis that the mean difference in accuracy between rf and svm is not significantly different from 0:\n",
      "[-0.01111111  0.02222222 -0.03370787  0.04494382  0.02247191  0.02247191\n",
      "  0.          0.01123596  0.03370787  0.02272727]\n",
      " Mean difference = 0.0135\n",
      "(1.8595170005581763, 0.095887131839307652)\n",
      "Test the hypothesis that the mean difference in AUC between rf and svm is not significantly different from 0:\n",
      "[ -2.22044605e-16  -1.03896104e-02  -6.95187166e-03   5.42780749e-02\n",
      "   0.00000000e+00   5.80213904e-02   9.62566845e-02   1.56149733e-01\n",
      "   8.47593583e-02   5.44662309e-04]\n",
      " Mean difference = 0.0433\n",
      "(2.4279302975547172, 0.038111709677769522)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHAhJREFUeJzt3X/0HXV95/Hni4QEIoYfm9OIAfZLETnIKj/qpmnXul9s\n1BxXjXZXY7Tg164a20Zxd5UQtq3xBxypurJn256NCAR7kFBRK1QkBeRLV3TdREkQ+AYT9Av5pVhC\nAC1KYt77x3y+MNzcH98fNzOTmdfjnHu4n5nPzP3MzfC+c18zd76KCMzMrD4OK3sAZmbWXy7sZmY1\n48JuZlYzLuxmZjXjwm5mVjMu7GZmNePCbrUl6Y8l/VTSE5KOLXs8UyFprqR/StvyqR59ByVt6zJ/\njaSP93+UVhUu7A0laVjSbkkzyh7LwSDpcOAzwO9HxOyIeKzg13+BpBsl7ZC0X9JJLfNnSrpK0uOS\ndkn6Lz1W+V7gkbQtH57i8CI9Oo39eElXStqZPkhGJK2SNEvSZknvarPMBZLWT3Fc1icu7A0kaQCY\nDzwCvLHg155e0Eu9ADgCGClpHPuBm4H/2GH+KuAU4CTgXOBCSa/tsr5/TYdtmSS1nSgdB3wHmAks\niIjZwKuBo9N41wDnt1n0vDTPqiAi/GjYA/gL4EbgvwM3tcw7EfgKWdH/Z+B/5ea9B7gfeAK4Dzgr\nTd8P/Gau3xrg4+n5ILAduBDYBVwDHAP8Q3qN3cBNwLzc8scBVwM70vyvpOn3Aq/P9Ts8jfHMlm14\nMfDzNK4ngdty4/wTYAvwYG6btgCPAl8Djs+tZz/wx2n+E8DHyIrbd4A9wFrg8B7v9fS0npNapu8A\nFubaHwWu67CONcDTwK/S9rwKmAFcntazA/gsMCP3nm/LLX828P20DWuB68b+fdq81ieATV225wRg\nb357gJeksR1X9r7tR/bwEXsznQ9cD/wd8FpJvwEgaRpZwf0x2RHiPLJCgKS3AB8BzovsKO6NZEW3\nndav+nOBY8mOTpeRfVO8MrVPAp4C/irX/2/JjrZfAvwGWdGC7EPhD3P9XgfsiIhNz3nxiB8CZ6Tm\n0RGxMDd7MfBvgZdIehVwKfAW4HjgobHtzXkNWWFcAKwArgCWpnG/ND2fkJT3Hw/kx31PbszPERFD\nwLXAZRHx/Ij4JvBnZN+6zkyP+Wla62vNAP6e7L07FvgS2beITlHMQrIP9rYiYjtwB9kR+pjzgK9H\nRKf9wYpW9ieLH8U+gFeQFdLnp/ZG4IPp+e+QHUUf1ma5dcD7O6yz9Yj9ap57xP4r0tFkh+XPAnan\n58cDvyYryK39Xkh2xHpUat8AfKjDOgfSuA5rGedgrn0l8Mlc+3lkR8Yn5fr/Tm7+BuDDufangc/2\neL8POGIn+1a0P/+ekMUdP+6ynmfe09TeCizKtV8ztjy5I3bglWQffvl13QV8rMPr/BB4b49tegew\nOT0/jOwDcXHZ+7Yfzz58xN487wT+MSKeTO0vpWmQFZyHImJ/m+VOAB6c5Gv+LCKeHmukk3CrJY1K\nehy4EzhaktIYdkfE460riYidZEXpP0k6BlhEdiQ7EfmrRcaO0sfW/wuySGZers9Pc8+fatM+aoKv\nD1lMBDA7N+1osg8tJP1vSU+mx0Ud1vHC/NiBh9O0dv12tEx7iA4ZO9n2t1tP3leB4yX9NtmHyCzg\n6z2WsQIVdSLLKkDSkcBbgcMk7UqTZwLHSHoZWdE7SdK0iPh1y+LbgBd1WPW/kP3PPeZ4nltAW7/2\n/zeyHHx+RDwi6SyyDFhpueMkHd2uuJNFCv+ZLF//dkTsatOnm/xYdpId2QMg6XnAv+LAQthXEfFY\nev/PAm5Lk88kO4dARLwPeF+P1YyNfeyE6klpWqtdPPeDCrKYbWuH9d4GvFnSRyMdkrcZ/79IuoEs\n0juS7NzAvh7jtQL5iL1Z3gTsA07n2Wz2dOD/kP1P+l2yQvDJdFR9hKTfTct+HviQpHOUeVHuEr6N\nwDskTZO0iOzrfzdHkR3tPp6uwvjI2IxUqL8B/I2kYyQdLim/vq8C5wAfAL4wyfdhzHXAuySdKWkm\nWd7+fyPi4S7LqMPzAztKR5CdKwA4IrXHfAH4s7SNpwPvpvtVJa2vdV1afo6kOWQnxP+2zXLfAfZJ\n+kB6L/+A7BxDJ/+D7JvENWP/vpLmSfqMpJfm+l0DvI0sr7+my/qsBC7szXI+cFVEbI+IR9Ljp2Qn\nLt+e+ryB7Mj8YbKj57cCRMQNwCXAF8murvgK2ck4gAvSco+l9Xy15XVbj/wuJzvS+2fg22SFPN/n\nPLIrLzaTRR8feGZFEb9Mrz1Al5N8HV73Oe2IuB34c+DLZEe7J5MVq07Lt07rej042TeZJ1KfzcAv\ncvM+QhZtPUR2MvKyiPjHLutqfa1PkGX+96THhjTtOeNMEdgfAENkMctbyba3/Ytk1/v/Ltn7/11J\nT5Adxe8hd5QfEf+Upm2LiO91GbeVQB2+bT3bITsCuxyYBnw+Ii5rmX8scBXwm8AvgT+KiPvGs6zZ\nZEj6c+DUiGh3PbVZ43Ut7OnytwfILoHaAawHlkbESK7Pp4AnIuLjkk4D/joiFo5nWbOJStHN98gu\nu/xW2eMxq6JeUcx8YGtEjEbEXrJrfBe39Dmd7KskEfEAMJCuix7PsmbjJuk9ZBHRN1zUzTrrVdjn\n8dyrG7Zz4Bn2TWQZHpLmk51xP2Gcy5qNW0RcERFHRcSflD0WsyrrVdjH85euP0l2udzdwHLgbrIf\nmPivZJuZlaDXdew7yH4wMuZEsiPvZ6QfuvzRWFvSj8nO9h/Za9nU3x8AZmaTEBFtL7ntVdg3AKem\nuwHuBJbQcm8MSUcDT0XE0ykDvTMifi6p57K9BmedTeYD0e+zlUnSqohYVfY46qJbDeha2CNin6Tl\nZPcJmQZcGREjkpal+avJbtS0Jr3IvWS/Cuy4bD82yDoXaWkoIta4gFsVDZQ9gKboeR37QR+AFD6S\n7B8XdqsqSWsiu1Ol9UG32ulfntbOUNkDMOtkTdkDaAoX9toZ/GjZIzBrJyKGyx5DU7iw146Gyx6B\nWTuSBsseQ1O4sJuZ1YxPnpqZHYJ88tTMrEFc2GvGOaZVlffN4riw187qobJHYGblcsZeMxIR0f1P\ntpnZoc8Zu5lZg7iw185w2QMwa8sZe3Fc2M3MasYZe804YzdrBmfszeJ7xZg1nAt77fheMVZNztiL\n48JuZlYzztjNzA5BztjNzBrEhb1mnGNaVXnfLI4Le+34XjFmTeeMvWZ8HbtZMzhjNzNrEBf22hku\newBmbTljL07Pwi5pkaTNkrZIWtFm/hxJt0jaKOleSUO5eSsl3SfpB5K+KGlmn8dvZmYtumbskqYB\nDwALgR3AemBpRIzk+qwCZkbESklzUv+5wAnAN4HTI+JXkq4Hbo6Ia1pewxl7HzljN2uGqWTs84Gt\nETEaEXuBtcDilj67gNnp+Wzg0YjYBzwB7AVmSZoOzCL7cLCDy/eKMWu4XoV9HrAt196epuVdAZwh\naSewCbgAICJ2A58BHgZ2Ansi4rZ+DNq68b1irJqcsRdneo/547kW8mJgY0QMSjoFuFXSy8jimA8C\nA8DjwJckvSMirm1dgaQ1wGhq7knrG07zBgHcHl8bOEtZHlOJ8bjtttv9aafnQ2RG6aJXxr4AWBUR\ni1J7JbA/Ii7L9bkZuCQi7krt24GLgJOB10TEu9P084AFEfGnLa/hjN3MbIKmkrFvAE6VNCBpBrAE\nuLGlz2ayk6tImgucBjxIdhJ1gaQjJSn1uX/ym2FmZuPRtbCnk6DLgXVkRfn6iBiRtEzSstTtUuDl\nkjYBtwEXRsTuiNgEfIHsw+Ge1PdzB2Mj7FnOMa2qvG8Wx7cUqBnpc2si3jtU9jjMWkkazJ0Lsinq\nVjtd2GvG17GbNcNUMnYzMzvEuLDXznDZAzBryxl7cVzYzcxqxhl7zThjN2sGZ+zN4nvFmDWcC3vt\n+F4xVk3O2Ivjwm5mVjPO2M3MDkHO2M3MGsSFvWacY1pVed8sjgt77aweKnsEZlYuZ+w14+vYzZrB\nGbuZWYO4sNfOcNkDMGvLGXtxXNjNzGrGGXvNOGM3awZn7M3ie8WYNZwLe+34XjFWTc7Yi+PCbmZW\nM87YzcwOQc7YzcwaxIW9ZpxjWlV53yxOz8IuaZGkzZK2SFrRZv4cSbdI2ijpXklDuXnHSLpB0oik\n+yUt6PP47QC+V4xZ03XN2CVNAx4AFgI7gPXA0ogYyfVZBcyMiJWS5qT+cyNin6RrgDsj4ipJ04Hn\nRcTjLa/hjL2PfB27WTNMJWOfD2yNiNGI2AusBRa39NkFzE7PZwOPpqJ+NPB7EXEVQETsay3qZmbW\nf70K+zxgW669PU3LuwI4Q9JOYBNwQZp+MvAzSVdL+r6kKyTN6segrZvhsgdg1pYz9uJM7zF/PNdC\nXgxsjIhBSacAt0o6M637HGB5RKyXdDlwEfAXrSuQtAYYTc09aX3Dad4ggNvja8NGpHMHqzIet912\nuz/t9HyIzChd9MrYFwCrImJRaq8E9kfEZbk+NwOXRMRdqX07sILs6P47EXFymv4K4KKIeH3Lazhj\n7yNn7GbNMJWMfQNwqqQBSTOAJcCNLX02k51cRdJc4DTgRxHxE2CbpBenfguB+ya5DY0ksVsiJvJI\ny01oGYndZW+rmfVP1ygmnQRdDqwDpgFXRsSIpGVp/mrgUuBqSZvIPigujIixQvF+4Nr0ofAg8K6D\ntB11dexEj74lPRPDjH+ZcUVuZlMymX3TJse3FKiwycQqky3sjm/sYHNh769utdOFvcKKKrgu7GaH\nnqlk7GZmdohxYa8ZXytsVeV9szgu7GZmNeOMvcKcsZtZJ91qZ69fnpqZTYikSR0t+gCvfxzF1Ixz\nTCtbRKjdA+7oOM9Fvb9c2M3MasYZe4U5Y7c68X7WX76O3cyq4KNlD6ApXNhrxhm7VZeGyx5BU7iw\nm5nVjDP2CnPGbmadOGM3M2sQF/aaccZuVeV9szgu7GZWkNVDZY+gKZyxV5gzdqsT72f95YzdzKxB\nXNhrxjmmVddw2QNoDBd2M7OaccZeYc7YrU68n/WXM3YzqwLfK6YgLuw144zdqsv3iilKz8IuaZGk\nzZK2SFrRZv4cSbdI2ijpXklDLfOnSbpb0k19HLeZmXXQNWOXNA14AFgI7ADWA0sjYiTXZxUwMyJW\nSpqT+s+NiH1p/n8Ffgt4fkS8sc1rOGPvwBm7mXUylYx9PrA1IkYjYi+wFljc0mcXMDs9nw08mivq\nJwCvAz4PLhxmZkXoVdjnAdty7e1pWt4VwBmSdgKbgAty8z4LfBjYP8Vx2jg5Y7eq8r5ZnOk95o/n\nWsiLgY0RMSjpFOBWSWcC/x54JCLu7vUPKmkNMJqae9L6htO8QQC3x9cGzlKWrUxg+TuAQaowfrfr\n3F49JGVf3KsxnkOrnZ4PkRmli14Z+wJgVUQsSu2VwP6IuCzX52bgkoi4K7VvBy4C3gycB+wDjiCL\nab4cEee3vIYz9g6csVudeD/rr6lk7BuAUyUNSJoBLAFubOmzmezkKpLmAqcBD0bExRFxYkScDLwN\n+GZrUTczs/7rWtjTSdDlwDrgfuD6iBiRtEzSstTtUuDlkjYBtwEXRsTudqvr47itA+eYVl3DZQ+g\nMXxLgQqbzFdXSYO5vP2gvY7ZREnDETHo/axPutVOF/YKc8ZudeL9rL98rxgzqwLfK6YgLuw144zd\nqsv3iimKC7uZWc04Y68wZ+xm1okzdjOzBnFhrxln7FZV3jeL48JuZgVZPVT2CJrCGXuFOWO3OvF+\n1l/O2M3MGsSFvWacY1p1DZc9gMZwYTczqxln7BXmjN3qxPtZf3Wrnb3+gpKZWVsSu4FjJ7jMRI8k\nH4vguAku03iOYmrGGbsV6NgINN4H6NyJ9E9H9xP64LCMC7uZWc04Y68wZ+xWZUXsN943O/N17GZm\nDeLCXjPO2K2qvG8Wx4XdzKxmnLFXmDN2qzJn7OVyxm5m1iAu7DXjHNOqyvtmccZV2CUtkrRZ0hZJ\nK9rMnyPpFkkbJd0raShNP1HSHZLuS9M/0Ofxm5lZi54Zu6RpwAPAQmAHsB5YGhEjuT6rgJkRsVLS\nnNR/LjAHeEFEbJR0FPA94E0tyzpj78AZu1WZM/ZyTTVjnw9sjYjRiNgLrAUWt/TZBcxOz2cDj0bE\nvoj4SURsBIiInwMjwAsnsxFmZjY+4yns84Btufb2NC3vCuAMSTuBTcAFrSuRNACcDXx3MgO18XGO\naVXlfbM447m743iuh7wY2BgRg5JOAW6VdGZEPAmQYpgbgAvSkftzSFoDjKbmnrSu4TRvEKCJ7UAM\np7vhDaY3Zzj9t1P7s8CwNO7+w8AdwNg/c5W23223YRjp3MGqjKfMdno+lL0vz9TLtsaTsS8AVkXE\notReCeyPiMtyfW4GLomIu1L7dmBFRGyQdDjwD8A3IuLyNut3xt6BM3arMmfs5Zpqxr4BOFXSgKQZ\nwBLgxpY+m8lOriJpLnAa8CNJAq4E7m9X1M3MrP96FvaI2AcsB9YB9wPXR8SIpGWSlqVulwIvl7QJ\nuA24MCJ2A/8O+EPgXEl3p8eig7IlBjjHtOryvlkc31KgwibzNVTSM3nkwXwds4nuN943+6tb7XRh\nrzBn7FZlztjLNdWM3czMDiEu7DXjHNOqyvtmcVzYzcxqxhl7hTljt0qTiikerg9tdaud4/nlqZnZ\nAURQyMnTg/kCNeUopmacY1pVed8sjgu7mVnNOGOvMGfsVmW+jr1cvo7dzKxBXNhrxjmmVZX3zeK4\nsJuZ1Ywz9gpzxm5V5oy9XM7YzcwaxIW9ZpxjWlV53yyOC7uZWc04Y68wZ+xWZc7Yy+WM3cysQVzY\na8Y5plWV983iuLCbmdWMM/YKc8ZuVeaMvVzO2M3MGsSFvWacY1pVed8sTs/CLmmRpM2Stkha0Wb+\nHEm3SNoo6V5JQ+Nd1szM+q9rxi5pGvAAsBDYAawHlkbESK7PKmBmRKyUNCf1nwtEr2XT8s7YO3DG\nblXmjL1cU8nY5wNbI2I0IvYCa4HFLX12AbPT89nAoxGxb5zLmplZn/Uq7POAbbn29jQt7wrgDEk7\ngU3ABRNY1vrMOaZVlffN4kzvMX8810JeDGyMiEFJpwC3SjpzIoOQtAYYTc09aX3Dad4ggNvjawNn\nKfv+OoHl7wAGqcL43XY734ZhpHMHqzKeMtvp+VD2vjxTL9vqlbEvAFZFxKLUXgnsj4jLcn1uBi6J\niLtS+3ZgBdmHRtdl03Rn7B04Y7cqc8Zerqlk7BuAUyUNSJoBLAFubOmzmewEKZLmAqcBPxrnsmZm\n1mddC3s6CbocWAfcD1wfESOSlklalrpdCrxc0ibgNuDCiNjdadmDtSGWcY5pVeV9szi+pUCFTeZr\nqKRn8siD+Tpm0rjOweUMM3YuZwIei+C4iS7UBN1qpwt7hTljtzrxftZfU8nYzczsEOPCXjPOMa26\nhsseQGO4sJuZ1Ywz9gpzxm514v2sv5yxm1kVfLTsATSFC3vNOGO36tJw2SNoChd2M7OaccZeYRP/\nAcik+UcgZoeYbrWz190drUSTOdHkE1Rm5iimdobLHoBZWz7/UxwXdjMryOqhskfQFM7Ya8ZRjFWV\n983+8nXsZmYN4sJeO5+7puwRmLU3XPYAGsOFvXaWrSl7BGZWLmfsZlYIZ+z95YzdzKrA94opiAt7\nzfhaYasu3yumKC7sZmY148JeOzFY9gjM2pnoH1m3yfPJ05rxCSqzZvDJ00YZLnsAZm35/E9xehZ2\nSYskbZa0RdKKNvM/JOnu9PiBpH2SjknzVkq6L03/oqSZB2MjzOxQ4HvFFKVrFCNpGvAAsBDYAawH\nlkbESIf+rwc+GBELJQ0A3wROj4hfSboeuDkirmlZxlFMHzmKsaryvtlfU4li5gNbI2I0IvYCa4HF\nXfq/HbguPX8C2AvMkjQdmEX24WBmZgdRr8I+D9iWa29P0w4gaRbwWuDLABGxG/gM8DCwE9gTEbdN\ndcDWi+8VY1U1XPYAGqPXX1CayCUzbwC+FRF7ACSdAnwQGAAeB74k6R0RcW3rgpLWAKOpuQfYOHZp\n1NgJF7fH14ZlG6Vlg1UZj9tuu92fdno+RGaULnpl7AuAVRGxKLVXAvsj4rI2fb8KXB8Ra1N7CfDq\niHh3ap8HLIiIP21Zzhm7WQM4Y++vqWTsG4BTJQ1ImgEsAW5s8wJHA68EvpabvBlYIOlISSI7AXv/\nZDbAzGrB94opSNfCHhH7gOXAOrKifH1EjEhaJmlZruubgHUR8VRu2U3AF8g+HO5Jkz/Xz8HbgXyt\nsFWX7xVTFP/ytGYkPZOvm1WJ983+8i9PG8X3irFqclEvjo/Ya8YnqMyawUfsjTJc9gDM2vL5n+K4\nsJtZQXyvmKI4iqkZRzFWVd43+8tRjJlZg7iw147vFWNVNVz2ABrDhb12lq0pewRmVi5n7GZWCGfs\n/eWM3cyqwPeKKYgLe834WmGrLt8rpigu7GZmNePCXju+V4xVk+8VUxyfPK0Zn6AyawafPG2U4bIH\nYNaWz/8Ux4XdzArie8UUxVFMzTiKsaryvtlfjmLMzBrEhb12fK8Yq6rhsgfQGC7steN7xZg13fSy\nB2CTI6njyRGpfYzpcxlWhO77Jh3nef/sHxf2Q5T/J7Cq8r5Zvp5RjKRFkjZL2iJpRZv5H5J0d3r8\nQNI+ScekecdIukHSiKT7JS04GBthz/K1wlZV3jeL07WwS5oG/BWwCHgJsFTS6fk+EfHpiDg7Is4G\nVgLDEbEnzf6fwM0RcTrwMmCk3xtgBzir7AGYdeB9syC9jtjnA1sjYjQi9gJrgcVd+r8duA5A0tHA\n70XEVQARsS8iHu/DmK27Y8oegFkH3jcL0quwzwO25drb07QDSJoFvBb4cpp0MvAzSVdL+r6kK1If\nMzM7iHoV9on8LPUNwLdyMcx04BzgbyLiHOAXwEUTH6JN0EDZAzDrYKDsATRFr6tidgAn5tonkh21\nt/M2UgyTbAe2R8T61L6BDoW92+VRNnGS3ln2GMza8b5ZjF6FfQNwqqQBYCewBFja2inl6a8ky9gB\niIifSNom6cUR8UNgIXBf67K+NMrMrL+6FvaI2CdpObAOmAZcGREjkpal+atT1zcB6yLiqZZVvB+4\nVtIM4EHgXX0dvZmZHaD0uzuamVl/+V4xNSTpLekHYbeXPRYzK55vKVAzym4U8x7g3RHx7bLHY2bF\n8xF7DUgakPSApGuAX5OdqL5K0l+WPDRrCEnPk/R1SRvTrUXOl/R3ufmDkm5Kz38u6S8l3SvpVkkL\nJN0p6UFJbyhvK+rDhb0+XgT8dUQcBtwJvD0iLix5TNYci4AdEXFWRLwU+HvgtyUdmeYv4dnLoWcB\nt0fEvwGeBD4GvAp4c3puU+TCXh8PRcT/y7V9GakV6R7g1ZI+KekVEfEEcAvwRknTgdcBX0t9n46I\nden5D4A7IuLXwL34R0x94Yy9Pn7R0vblTlaYiNgi6WzgPwCfSCfu1wLLgd3AhogY20f35hbdDzyd\n1rE/fQjYFPmI3cymTNLxwC8j4lrg08DZZJHgb5GdzL+uy+LWZ/50rA8foVuZXgp8StJ+siPy96Uj\n8JuAdwLn5/q27qvRZZ5Ngn+gZGZWM45izMxqxoXdzKxmXNjNzGrGhd3MrGZc2M3MasaF3cysZlzY\nzcxqxoXdzKxm/j89fhJ1Vuz1kAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109082690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPWNgl6SeMbBLUs8Y2CWpZ/4/tQZek/Vqj1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109082810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "for alg in acc_dict:  \n",
    "    all_acc = np.array(acc_dict[alg])\n",
    "    all_auc = np.array(auc_dict[alg])\n",
    "    print \"95% C.I. for both accuracy and AUC based on CV\"    \n",
    "    print(\"Mean Accuracy: %0.2f (+/- %0.2f)\" % (all_acc.mean(), all_acc.std() * 1.96))\n",
    "    print(all_auc)\n",
    "    print(\"Mean AUC: %0.2f (+/- %0.2f)\" % (all_acc.mean(), all_auc.std() * 1.96))\n",
    "\n",
    "dfacc = pd.DataFrame(np.c_[acc_dict['rf'], acc_dict['svm']], columns=['rf','svm'])    \n",
    "dfacc.plot(kind='box', title='Accuracy from 10-fold CV')\n",
    "dfauc = pd.DataFrame(np.c_[auc_dict['rf'], auc_dict['svm']], columns=['rf','svm'])    \n",
    "dfauc.plot(kind='box', title='AUC from 10-fold CV')\n",
    "\n",
    "diff_acc = np.array(acc_dict['rf']) - np.array(acc_dict['svm'])\n",
    "diff_auc = np.array(auc_dict['rf']) - np.array(auc_dict['svm'])\n",
    "\n",
    "print 'Test the hypothesis that the mean difference in accuracy between rf and svm is not significantly different from 0:'\n",
    "print(diff_acc)\n",
    "print ' Mean difference = %0.4f' % diff_acc.mean()\n",
    "print(stats.ttest_1samp(diff_acc, popmean=0))\n",
    "print 'Test the hypothesis that the mean difference in AUC between rf and svm is not significantly different from 0:'\n",
    "print(diff_auc)\n",
    "print ' Mean difference = %0.4f' % diff_auc.mean()\n",
    "print(stats.ttest_1samp(diff_auc, popmean=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean difference in accuracy and AUC indicates that rf performs slightly better than SVM, however we need to check if the difference is statistically significant or not using one-sample t-test.\n",
    "\n",
    "The p-value for the one-sample t-test on difference in accuracy is 0.10 >0.05, which means we can't reject the null hypothesis that there is no significant difference in accuracy between RF and SVM. \n",
    "\n",
    "Whilst the p-values for the t-test on difference in AUC is 0.04, which is marginally signifcantly different from 0 at signficance level of 0.05.\n",
    "\n",
    "More details on how to explain the t-test results, please see \n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've determined the model we are going to use and the desired values for our tuning parameters, we can fill in the -1 values in the column Age with the mean and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      23.600640\n",
       "std       17.867496\n",
       "min       -1.000000\n",
       "25%        6.000000\n",
       "50%       24.000000\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].map(lambda x: age_mean if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.699118\n",
       "std       13.002015\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       29.699118\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 50, max_features=0.5, max_depth=5)\n",
    "model = model.fit(train_data[0:,2:],train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill in the NA values in test data with the mean, since there is no analogous problem of snooping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['Age'] = df_test['Age'].fillna(age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/savarin/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/index.py:503: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n",
      "  type(self).__name__),FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "test_data = df_test.values\n",
    "\n",
    "output = model.predict(test_data[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('../results/titanic_1-4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
