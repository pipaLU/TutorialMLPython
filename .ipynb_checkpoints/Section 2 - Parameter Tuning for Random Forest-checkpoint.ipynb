{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1-3 - Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous sections, we took the approach of using Scikit-learn as a black box. We now review how to tune the parameters of the model to make more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:198: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "df['Age'] = df['Age'].fillna(age_mean)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for the Random Forest Classifier details the different input parameters of the model. These input parameters include the number of trees, and the number of branches each tree has. It is unclear, off-the-bat, which values would be optimal. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV allows us to test the desired range of input parameters, and review the performance of each set of values on a cross-validation basis. Here we review the number of features considered at each step a branch is made (max_features: 50% or 100% of features) and the maximum number of branches (max_depth: 5 levels or no limitations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameter_grid = {\n",
    "    'max_features': [0.5, 1.],\n",
    "    'max_depth': [5., None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators = 100), parameter_grid,\n",
    "                            cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.821229 -   0.6s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.826816 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.831461 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.792135 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.853107 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.798883 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.821229 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.831461 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.786517 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.847458 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.782123 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.798883 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.859551 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.775281 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.853107 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.787709 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.832402 -   0.4s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.853933 -   0.4s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.775281 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.830508 -   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_features': [0.5, 1.0], 'max_depth': [5.0, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_data[0:,2:], train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now review the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.82492, std: 0.01964, params: {'max_features': 0.5, 'max_depth': 5.0},\n",
       " mean: 0.81706, std: 0.02196, params: {'max_features': 1.0, 'max_depth': 5.0},\n",
       " mean: 0.81369, std: 0.03563, params: {'max_features': 0.5, 'max_depth': None},\n",
       " mean: 0.81594, std: 0.02959, params: {'max_features': 1.0, 'max_depth': None}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the results, and determine the best-performing tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5.0, 'max_features': 0.5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "grid_search.best_score_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set these tuning parameters to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, max_features=0.5, max_depth=5.0)\n",
    "model = model.fit(train_data[0:,2:],train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Write the code so that grid_search refits model with the best tuning parameters to the entire dataset after these parameters are found, and hence allow us to skip the two lines of code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/pandas/core/index.py:667: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n",
      "  type(self).__name__),FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "\n",
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "test_data = df_test.values\n",
    "\n",
    "output = model.predict(test_data[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('titanic/titanic_1-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
