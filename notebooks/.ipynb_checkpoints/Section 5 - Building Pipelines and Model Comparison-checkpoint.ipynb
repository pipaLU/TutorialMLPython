{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5 - Model Comparison using Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV reviews the performance of a set range of parameters on a cross-validation basis. This means only a portion of the training data is reviewed at any one time. When filling in the NA values with the mean value or feature selection, however, we considered the whole set of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we took an inconsistent approach in reviewing only a portion of the data when running GridSearchCV, but the full set of data when filling in missing values. We can avoid this inconsistency by building pipelines and making imputations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will leave the NA values in the column Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:198: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the NA values in the column Age with a negative value marker -1, as the following bug disallows us from using a missing value marker:\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/3044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then review our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived       891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Gender         891 non-null int64\n",
      "Embarked_C     891 non-null float64\n",
      "Embarked_Q     891 non-null float64\n",
      "Embarked_S     891 non-null float64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 83.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building pipelines\n",
    "We now build pipelines to enable us to first impute the mean value of the column Age on the portion of the training data we are considering, scale the data, select the features, and then assess the performance of our tuning parameters with various learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building a pipeline for random forest model (rf)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "anova_filter = SelectKBest(f_regression)\n",
    "imputer = Imputer(strategy='mean', missing_values=-1)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('imp', imputer),\n",
    "    ('anova', anova_filter),\n",
    "    ('rf', clf)\n",
    "])\n",
    "\n",
    "# Building a pipeline for SVM classification model (svc)\n",
    "# Normalisation is important to SVM, unlike for decision tree learning. \n",
    "\n",
    "# ANOVA SVM-C\n",
    "clf = SVC(kernel='rbf')\n",
    "pipeline_svm = Pipeline([\n",
    "        ('imp', imputer),\n",
    "        ('scale', scaler), \n",
    "        ('anova', anova_filter), \n",
    "        ('svc', clf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Grid search using pipelines\n",
    "\n",
    "We now setup parameter grid and run GridSearchCV as before but replacing the classifier with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=100, score=0.782123 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=100, score=0.826816 -   0.1s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=100, score=0.865169 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=100, score=0.775281 -   0.1s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=100, score=0.847458 -   0.1s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=1000, score=0.798883 -   1.4s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=1000, score=0.826816 -   1.6s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=1000, score=0.831461 -   1.7s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=1000, score=0.786517 -   1.4s\n",
      "[CV] rf__max_depth=5, anova__k=8, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=8, rf__n_estimators=1000, score=0.841808 -   1.4s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=100, score=0.770950 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=100, score=0.798883 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=100, score=0.859551 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=100, score=0.786517 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=100, score=0.841808 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=1000, score=0.759777 -   2.7s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=1000, score=0.804469 -   2.7s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=1000, score=0.848315 -   2.0s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=1000, score=0.775281 -   1.7s\n",
      "[CV] rf__max_depth=None, anova__k=8, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=8, rf__n_estimators=1000, score=0.824859 -   2.0s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=100, score=0.798883 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=100, score=0.821229 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=100, score=0.853933 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=100, score=0.786517 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=100 ...............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=100, score=0.841808 -   0.2s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=1000, score=0.798883 -   1.5s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=1000, score=0.821229 -   1.9s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=1000, score=0.825843 -   1.5s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=1000, score=0.786517 -   1.8s\n",
      "[CV] rf__max_depth=5, anova__k=9, rf__n_estimators=1000 ..............\n",
      "[CV]  rf__max_depth=5, anova__k=9, rf__n_estimators=1000, score=0.853107 -   1.5s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=100, score=0.776536 -   0.4s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=100, score=0.793296 -   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  32 jobs       | elapsed:   30.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=100, score=0.848315 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=100, score=0.786517 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=100 ............\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=100, score=0.830508 -   0.2s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=1000, score=0.782123 -   2.0s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=1000, score=0.810056 -   2.1s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=1000, score=0.853933 -   1.8s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=1000, score=0.769663 -   1.8s\n",
      "[CV] rf__max_depth=None, anova__k=9, rf__n_estimators=1000 ...........\n",
      "[CV]  rf__max_depth=None, anova__k=9, rf__n_estimators=1000, score=0.830508 -   1.8s\n",
      "0.820426487093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   40.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'rf__max_depth': 5, 'anova__k': 9, 'rf__n_estimators': 100}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.793296 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.804469 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.769663 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.775281 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=6, svc__C=0.1, score=0.790960 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.754190 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.815642 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.831461 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.775281 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=6, svc__C=0.1, score=0.802260 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=6, svc__C=1, score=0.798883 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=6, svc__C=1, score=0.821229 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=6, svc__C=1, score=0.837079 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=6, svc__C=1, score=0.792135 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=6, svc__C=1, score=0.819209 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=6, svc__C=1, score=0.787709 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=6, svc__C=1, score=0.804469 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=6, svc__C=1, score=0.803371 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=6, svc__C=1, score=0.769663 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=6, svc__C=1, score=0.824859 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.798883 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.821229 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.831461 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.780899 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=6, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=6, svc__C=10, score=0.841808 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.798883 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.743017 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.814607 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.786517 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=6, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=6, svc__C=10, score=0.824859 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=9, svc__C=0.1, score=0.815642 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=9, svc__C=0.1, score=0.804469 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=9, svc__C=0.1, score=0.808989 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=9, svc__C=0.1, score=0.797753 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=0.1 ..........................\n",
      "[CV] . svc__gamma=0.1, anova__k=9, svc__C=0.1, score=0.807910 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=9, svc__C=0.1, score=0.793296 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=9, svc__C=0.1, score=0.759777 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=9, svc__C=0.1, score=0.747191 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=9, svc__C=0.1, score=0.713483 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=0.1 ............................\n",
      "[CV] ... svc__gamma=1, anova__k=9, svc__C=0.1, score=0.683616 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=9, svc__C=1, score=0.837989 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=9, svc__C=1, score=0.815642 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=9, svc__C=1, score=0.808989 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=9, svc__C=1, score=0.797753 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=1 ............................\n",
      "[CV] ... svc__gamma=0.1, anova__k=9, svc__C=1, score=0.858757 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=9, svc__C=1, score=0.770950 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=9, svc__C=1, score=0.776536 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=9, svc__C=1, score=0.820225 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=9, svc__C=1, score=0.786517 -   0.0s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=1 ..............................\n",
      "[CV] ..... svc__gamma=1, anova__k=9, svc__C=1, score=0.830508 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=9, svc__C=10, score=0.815642 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=9, svc__C=10, score=0.821229 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=9, svc__C=10, score=0.820225 -   0.0s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=9, svc__C=10, score=0.764045 -   0.1s\n",
      "[CV] svc__gamma=0.1, anova__k=9, svc__C=10 ...........................\n",
      "[CV] .. svc__gamma=0.1, anova__k=9, svc__C=10, score=0.853107 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=9, svc__C=10, score=0.776536 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=9, svc__C=10, score=0.765363 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=9, svc__C=10, score=0.825843 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=9, svc__C=10, score=0.814607 -   0.1s\n",
      "[CV] svc__gamma=1, anova__k=9, svc__C=10 .............................\n",
      "[CV] .... svc__gamma=1, anova__k=9, svc__C=10, score=0.790960 -   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 jobs       | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.82379349046\n",
      "{'svc__gamma': 0.1, 'anova__k': 9, 'svc__C': 1}\n"
     ]
    }
   ],
   "source": [
    "pipeline_dict = {'rf': pipeline_rf, 'svm': pipeline_svm} \n",
    "parameter_grid_dict = {}\n",
    "parameter_grid_dict['rf'] = {\n",
    "            'anova__k': [8, 9],\n",
    "            'rf__n_estimators': [100, 1000],\n",
    "            'rf__max_depth': [5, None],\n",
    "        }\n",
    "\n",
    "parameter_grid_dict['svm'] = {\n",
    "            'anova__k': [6, 9],\n",
    "            'svc__C': [0.1, 1, 10],\n",
    "            'svc__gamma': [0.1, 1]\n",
    "        }\n",
    "\n",
    "grid_results = {}\n",
    "for alg in ['rf', 'svm']:\n",
    "    pipeline = pipeline_dict[alg]\n",
    "    parameter_grid = parameter_grid_dict[alg]    \n",
    "    grid_search = GridSearchCV(pipeline, parameter_grid, cv=5, verbose=3)\n",
    "    grid_search.fit(train_data[0::,2::], train_data[0::,0])\n",
    "\n",
    "    sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    grid_results[alg] = grid_search    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for rf :\n",
      "0.826038159371\n",
      "{'rf__max_depth': 5, 'anova__k': 9, 'rf__n_estimators': 1000}\n",
      "Best accuracy for svm :\n",
      "0.822671156004\n",
      "{'svc__gamma': 0.1, 'anova__k': 9, 'svc__C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the grid search results \n",
    "for alg in grid_results:\n",
    "    grid_search = grid_results[alg]\n",
    "    sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "    print 'Best accuracy for %s :' % alg\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark:\n",
    "Univariate ANOVA feature selection doesn't seem to improve the performance for both RF and SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation to estimate accuracy and AUC using the selected tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values=-1, strategy='mean', verbose=0)), ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('anova', SelectKBest(k=9, score_func=<function f_regression at 0x106a43b18>)), ('svc', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the parameters of the models to the best ones selected from grid search\n",
    "pipeline_rf.set_params(anova__k=9, rf__n_estimators=1000, rf__max_depth=5)\n",
    "pipeline_svm.set_params(anova__k=9, svc__C=1, svc__gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compare performance of different models, perform CV using the best hyper-parameters selected using grid search based on the previous pipeline analysis. This time we use two runs of 5-fold CV in order to get more reliable estimate of the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CV using rf ---\n",
      "[CV]Prediction accuracy: 0.793296089385\n",
      "[CV]           AUC:0.845191040843\n",
      "[CV]Prediction accuracy: 0.826815642458\n",
      "[CV]           AUC:0.822529644269\n",
      "[CV]Prediction accuracy: 0.831460674157\n",
      "[CV]           AUC:0.876804812834\n",
      "[CV]Prediction accuracy: 0.786516853933\n",
      "[CV]           AUC:0.882152406417\n",
      "[CV]Prediction accuracy: 0.858757062147\n",
      "[CV]           AUC:0.908121964382\n",
      "[CV]Prediction accuracy: 0.810055865922\n",
      "[CV]           AUC:0.847957839262\n",
      "[CV]Prediction accuracy: 0.826815642458\n",
      "[CV]           AUC:0.823056653491\n",
      "[CV]Prediction accuracy: 0.842696629213\n",
      "[CV]           AUC:0.876871657754\n",
      "[CV]Prediction accuracy: 0.786516853933\n",
      "[CV]           AUC:0.878676470588\n",
      "[CV]Prediction accuracy: 0.858757062147\n",
      "[CV]           AUC:0.910280626012\n",
      "Mean Accuracy: 0.822 (+/- 0.051)\n",
      "Mean AUC: 0.867 (+/- 0.058)\n",
      "--- CV using svm ---\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.837988826816\n",
      "[CV]           AUC:0.835704874835\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.815642458101\n",
      "[CV]           AUC:0.855335968379\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.808988764045\n",
      "[CV]           AUC:0.870387700535\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.797752808989\n",
      "[CV]           AUC:0.816911764706\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.858757062147\n",
      "[CV]           AUC:0.892066918511\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.837988826816\n",
      "[CV]           AUC:0.835704874835\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.815642458101\n",
      "[CV]           AUC:0.855335968379\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.808988764045\n",
      "[CV]           AUC:0.870387700535\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.797752808989\n",
      "[CV]           AUC:0.816911764706\n",
      "No probability output, use decision function instead!\n",
      "[CV]Prediction accuracy: 0.858757062147\n",
      "[CV]           AUC:0.892066918511\n",
      "Mean Accuracy: 0.824 (+/- 0.043)\n",
      "Mean AUC: 0.854 (+/- 0.051)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold as SKFold\n",
    "\n",
    "X = train_data[0:, 2:]\n",
    "y = train_data[0:, 0]\n",
    "\n",
    "scv1 = SKFold(y=y, n_folds=5, random_state=1234)\n",
    "scv2 = SKFold(y=y, n_folds=5, random_state=5678)\n",
    "\n",
    "def getAccAuc(pipeline, X_train, y_train, X_test, y_test):\n",
    "    \"\"\" To calculate accuracy and auc using different training test sets \n",
    "    given a predefined modelling pipeline.\n",
    "    \"\"\"\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # Get prediction on class label from the model\n",
    "    y_prediction = pipeline.predict(X_test)\n",
    "    \n",
    "    # Get probability or decision function output from the model\n",
    "    try:\n",
    "         y_out = pipeline.predict_proba(X_test)[:,1]                     \n",
    "    except AttributeError:\n",
    "         print \"No probability output, use decision function instead!\"\n",
    "         y_out = pipeline.decision_function(X_test)\n",
    "    \n",
    "    acc = np.sum(y_test == y_prediction)*1./len(y_test)\n",
    "    print \"[CV]Prediction accuracy:\", acc\n",
    "    # Compute area under the ROC curve (AUC)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_out)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"[CV]           AUC:%s\"%roc_auc)\n",
    "    return([acc, roc_auc])\n",
    "\n",
    "\n",
    "pipeline_dict = {'rf': pipeline_rf, 'svm': pipeline_svm}\n",
    "acc_dict = {}\n",
    "auc_dict = {}\n",
    "for alg in ['rf', 'svm']:  \n",
    "  pipeline = pipeline_dict[alg]\n",
    "  mean_acc = 0.0\n",
    "  mean_auc = 0.0\n",
    "  all_acc = []\n",
    "  all_auc = []\n",
    "  print '--- CV using %s ---' % alg\n",
    "  \n",
    "  for scv in [scv1, scv2]:\n",
    "     for training_set, test_set in scv:\n",
    "        X_train = X[training_set]\n",
    "        y_train = y[training_set]\n",
    "        X_test = X[test_set]\n",
    "        y_test = y[test_set]\n",
    "\n",
    "        [acc, roc_auc] = getAccAuc(pipeline, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "        all_acc.append(acc)\n",
    "        all_auc.append(roc_auc)\n",
    "        acc_dict[alg] = all_acc\n",
    "        auc_dict[alg] = all_auc\n",
    "    \n",
    "  all_acc=np.asarray(all_acc)\n",
    "  all_auc=np.asarray(all_auc)\n",
    "  acc_dict[alg] = all_acc\n",
    "  auc_dict[alg] = all_auc\n",
    "\n",
    "  # print 95% C.I. for both accuracy and AUC based on CV\n",
    "  print(\"Mean Accuracy: %0.3f (+/- %0.3f)\" % (all_acc.mean(), all_acc.std() * 1.96))\n",
    "  print(\"Mean AUC: %0.3f (+/- %0.3f)\" % (all_auc.mean(), all_auc.std() * 1.96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Comparison of model performance from CV\n",
    "We now can start to compare the CV performance for the two type of models: rf and svm using boxplots and one sample (student) t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== rf === \n",
      "95% C.I. for both accuracy and AUC based on CV for \n",
      "[ 0.79329609  0.82681564  0.83146067  0.78651685  0.85875706  0.81005587\n",
      "  0.82681564  0.84269663  0.78651685  0.85875706]\n",
      "Mean Accuracy: 0.822 (+/- 0.051)\n",
      "[ 0.84519104  0.82252964  0.87680481  0.88215241  0.90812196  0.84795784\n",
      "  0.82305665  0.87687166  0.87867647  0.91028063]\n",
      "Mean AUC: 0.867 (+/- 0.058)\n",
      "=== svm === \n",
      "95% C.I. for both accuracy and AUC based on CV for \n",
      "[ 0.83798883  0.81564246  0.80898876  0.79775281  0.85875706  0.83798883\n",
      "  0.81564246  0.80898876  0.79775281  0.85875706]\n",
      "Mean Accuracy: 0.824 (+/- 0.043)\n",
      "[ 0.83570487  0.85533597  0.8703877   0.81691176  0.89206692  0.83570487\n",
      "  0.85533597  0.8703877   0.81691176  0.89206692]\n",
      "Mean AUC: 0.854 (+/- 0.051)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1096eb050>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n48JuZlYzLuxmZjXjwm5mVjP/H5PjE6SzS/iFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aa89990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEdEwKewREQ3z/wGp8ABlsp/pkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10957f850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "for alg in acc_dict:  \n",
    "    all_acc = np.array(acc_dict[alg])\n",
    "    all_auc = np.array(auc_dict[alg])\n",
    "    print \"===\", alg, \"=== \"\n",
    "    print \"95% C.I. for both accuracy and AUC based on CV for \"\n",
    "    print(all_acc)    \n",
    "    print(\"Mean Accuracy: %0.3f (+/- %0.3f)\" % (all_acc.mean(), all_acc.std() * 1.96))\n",
    "    print(all_auc)\n",
    "    print(\"Mean AUC: %0.3f (+/- %0.3f)\" % (all_auc.mean(), all_auc.std() * 1.96))\n",
    "\n",
    "dfacc = pd.DataFrame(np.c_[acc_dict['rf'], acc_dict['svm']], columns=['rf','svm'])    \n",
    "dfacc.plot(kind='box', title='Accuracy from 10-fold CV')\n",
    "dfauc = pd.DataFrame(np.c_[auc_dict['rf'], auc_dict['svm']], columns=['rf','svm'])    \n",
    "dfauc.plot(kind='box', title='AUC from 10-fold CV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the hypothesis that the mean difference in accuracy between rf and svm is not significantly different from 0:\n",
      "[-0.04469274  0.01117318  0.02247191 -0.01123596  0.         -0.02793296\n",
      "  0.01117318  0.03370787 -0.01123596  0.        ]\n",
      " Mean difference = -0.002\n",
      "(-0.22473331643930144, 0.8272061402609201)\n",
      "Test the hypothesis that the mean difference in AUC between rf and svm is not significantly different from 0:\n",
      "[ 0.00948617 -0.03280632  0.00641711  0.06524064  0.01605505  0.01225296\n",
      " -0.03227931  0.00648396  0.06176471  0.01821371]\n",
      " Mean difference = 0.013\n",
      "(1.2807844215330364, 0.23228820164956943)\n"
     ]
    }
   ],
   "source": [
    "diff_acc = np.array(acc_dict['rf']) - np.array(acc_dict['svm'])\n",
    "diff_auc = np.array(auc_dict['rf']) - np.array(auc_dict['svm'])\n",
    "\n",
    "print 'Test the hypothesis that the mean difference in accuracy between rf and svm is not significantly different from 0:'\n",
    "print(diff_acc)\n",
    "print ' Mean difference = %0.3f' % diff_acc.mean()\n",
    "print(stats.ttest_1samp(diff_acc, popmean=0))\n",
    "print 'Test the hypothesis that the mean difference in AUC between rf and svm is not significantly different from 0:'\n",
    "print(diff_auc)\n",
    "print ' Mean difference = %0.3f' % diff_auc.mean()\n",
    "print(stats.ttest_1samp(diff_auc, popmean=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "\n",
    "1. The mean difference in accuracy and AUC indicates that rf performs slightly better than SVM in auc. The variances in accuracy and AUC for RF are slightly higher than for SVM. And the 95% C.I. of Accuracy for the RF and for SVM indeed overlap, thus the accuracy for RF is not significantly different from SVM (at significance level of 0.05). The same applies to AUC. \n",
    "\n",
    "2. The p-value for the one-sample t-test on difference in accuracy is 0.72 >0.05, which reconfirms that we can't reject the null hypothesis that there is no significant difference in accuracy between RF and SVM. \n",
    "\n",
    "3. Whilst the p-value for the t-test on difference in AUC is 0.22, thus we can't reject the null hypothesis that there is no significant difference in AUC between RF and SVM. \n",
    "\n",
    "More details on how to perform t-tests using scipy, please see: \n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sikit-learn - Model training\n",
    "Now that we've determined the model we are going to use and the desired values for our tuning parameters, we can fill in the -1 values in the column Age with the mean and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      23.600640\n",
       "std       17.867496\n",
       "min       -1.000000\n",
       "25%        6.000000\n",
       "50%       24.000000\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].map(lambda x: age_mean if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.699118\n",
       "std       13.002015\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       29.699118\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 1000, max_depth=5)\n",
    "model = model.fit(train_data[0:,2:],train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill in the NA values in test data with the mean, since there is no analogous problem of snooping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.154603</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>12.636666</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  418.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.154603    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   12.636666    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   23.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   29.699118    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   35.750000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/pandas/core/index.py:667: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n",
      "  type(self).__name__),FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "test_data = df_test.values\n",
    "\n",
    "output = model.predict(test_data[0::,1::])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('../results/titanic_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking verions\n",
    "\n",
    "Finally, checking the versions of python and relevant libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:  sys.version_info(major=2, minor=7, micro=9, releaselevel='final', serial=0)\n",
      "Pandas:  0.16.0\n",
      "Sklearn:  0.16.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "print 'Python: ', sys.version_info\n",
    "print 'Pandas: ', pd.__version__\n",
    "print 'Sklearn: ', sklearn.__version__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
