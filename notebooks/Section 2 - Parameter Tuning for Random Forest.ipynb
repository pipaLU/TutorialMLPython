{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous sections, we took the approach of using Scikit-learn as a black box. We now review how to tune the parameters of the model to make more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:198: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "df['Age'] = df['Age'].fillna(age_mean)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  PassengerId  Pclass        Age  SibSp  Parch     Fare  Gender  \\\n",
       "0         0            1       3  22.000000      1      0   7.2500       1   \n",
       "1         1            2       1  38.000000      1      0  71.2833       0   \n",
       "2         1            3       3  26.000000      0      0   7.9250       0   \n",
       "3         1            4       1  35.000000      1      0  53.1000       0   \n",
       "4         0            5       3  35.000000      0      0   8.0500       1   \n",
       "5         0            6       3  29.699118      0      0   8.4583       1   \n",
       "6         0            7       1  54.000000      0      0  51.8625       1   \n",
       "7         0            8       3   2.000000      3      1  21.0750       1   \n",
       "8         1            9       3  27.000000      0      2  11.1333       0   \n",
       "9         1           10       2  14.000000      1      0  30.0708       0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  \n",
       "5           0           1           0  \n",
       "6           0           0           1  \n",
       "7           0           0           1  \n",
       "8           0           0           1  \n",
       "9           1           0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for the Random Forest Classifier details the different input parameters of the model. These input parameters include the number of trees, and the number of branches each tree has. It is unclear, off-the-bat, which values would be optimal. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV allows us to test the desired range of input parameters, and review the performance of each set of values on a cross-validation basis. Here we review the number of features considered at each step a branch is made (max_features: 50% or 100% of features) and the maximum number of branches (max_depth: 5 levels or no limitations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameter_grid = {\n",
    "    'max_features': [0.5, 1.],\n",
    "    'max_depth': [5., None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators = 100), parameter_grid,\n",
    "                            cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.798883 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.821229 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.820225 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.792135 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.847458 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.798883 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.826816 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.825843 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.786517 -   0.4s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.853107 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.798883 -   0.5s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.793296 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.842697 -   0.2s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.775281 -   0.3s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.858757 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.798883 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.821229 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.859551 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.775281 -   0.2s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.847458 -   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_features': [0.5, 1.0], 'max_depth': [5.0, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_data[0:,2:], train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now review the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.81594, std: 0.01948, params: {'max_features': 0.5, 'max_depth': 5.0},\n",
       " mean: 0.81818, std: 0.02336, params: {'max_features': 1.0, 'max_depth': 5.0},\n",
       " mean: 0.81369, std: 0.03157, params: {'max_features': 0.5, 'max_depth': None},\n",
       " mean: 0.82043, std: 0.03087, params: {'max_features': 1.0, 'max_depth': None}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the results, and determine the best-performing tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820426487093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "print(grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set these tuning parameters to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, max_features=0.5, max_depth=5.0)\n",
    "model = model.fit(train_data[0:,2:],train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Write the code so that grid_search refits model with the best tuning parameters to the entire dataset after these parameters are found, and hence allow us to skip the two lines of code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    84.154687\n",
      "2    20.662183\n",
      "3    13.675550\n",
      "Name: Fare, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/pandas/core/index.py:667: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n",
      "  type(self).__name__),FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "\n",
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "\n",
    "print(fare_means)\n",
    "\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "test_data = df_test.values\n",
    "\n",
    "output = model.predict(test_data[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('../results/titanic_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
